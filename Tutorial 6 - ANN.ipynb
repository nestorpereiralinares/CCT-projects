{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50718908",
   "metadata": {},
   "source": [
    "# Tutorial 6 \n",
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409e43a",
   "metadata": {},
   "source": [
    "## Preprocess data for use in a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cf161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d062e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca84d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing a random seed ensures reproducible results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(9)\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e459b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "from sklearn import preprocessing\n",
    "import  numpy  as  np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings\n",
    "\n",
    "#Create features\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                     [-200.2, -234.1],\n",
    "                     [5000.5, 150.1],\n",
    "                     [6000.6, -125.1],\n",
    "                     [9000.9, -673.1]])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83adf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a standardizer\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "#Convert features\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "#Display features\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2e65b",
   "metadata": {},
   "source": [
    "## Designing a Neural Network\n",
    "* We will create a two-layer neural network (when counting layers we don’t include the input layer because it does not have any parameters to learn) using Keras’ sequential model. \n",
    "* Each layer is “dense” (also called fully connected), meaning that all the units in the previous layer are connected to all the neurals in the next layer. \n",
    "* In the first hidden layer we set units=16, meaning that layer contains 16 units with ReLU activation functions: activation='relu'. \n",
    "* In Keras, the first hidden layer of any network has to include an input_shape parameter, which is the shape of feature data. For example, (10,) tells the first layer to expect each observation to have 10 feature values. \n",
    "* In second layer is the same as the first, without the need for the input_shape parameter. This network is designed for binary classification so the output layer contains only one unit with a sigmoid activation function, which constrains the output to between 0 and 1 (representing the probability an observation is class 1).\n",
    "\n",
    "* Finally, before we can train our model, we need to tell Keras how we want our network to learn. We do this using the compile method, with our optimization algorithm (RMSProp), loss function (binary_crossentropy), and one or more performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b70df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Load Data.\n",
    "## Define Keras Model.\n",
    "## Compile Keras Model.\n",
    "## Fit Keras Model.\n",
    "## Evaluate Keras Model.\n",
    "## Tie It All Together.\n",
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fb993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Start creating neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Added fully connected layer using ReLU as activation function\n",
    "network.add(layers.Dense(units = 16, activation = \"relu\", input_shape=(10,)))\n",
    "\n",
    "# Added fully connected layer using ReLU as activation function\n",
    "network.add(layers.Dense(units = 16, activation = \"relu\"))\n",
    "\n",
    "# Added fully connected layer that uses sigmoid function as activation function\n",
    "network.add(layers.Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "#Compile neural network\n",
    "network . compile ( loss = \"binary_crossentropy\" , # cross entropy\n",
    "                optimizer = \"rmsprop\" ,   # root mean square propagation method\n",
    "                metrics = [ \"accuracy\" ]) # performance indicators は accuracy\n",
    "\n",
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72e7ec",
   "metadata": {},
   "source": [
    "* For each layer in the hidden and output layers we must define the number of units to include in the layer and the activation function. Overall, the more units we have in a layer, the more our network is able to learn complex patterns. However, more units might make our network overfit the training data in a way detrimental to the performance on the test data.\n",
    "\n",
    "For hidden layers, a popular activation function is the rectified linear unit (ReLU):\n",
    "\n",
    "f ( z ) = max ( 0 , z )\n",
    "\n",
    "where z is the sum of the weighted inputs and bias. As we can see, if z is greater than 0, the activation function returns z; otherwise, the function returns 0. This simple activation function has a number of desirable properties (a discussion of which is beyond the scope of this book) and this has made it a popular choice in neural networks. We should be aware, however, that many dozens of activation functions exist.\n",
    "\n",
    "* Second, we need to define the number of hidden layers to use in the network. More layers allow the network to learn more complex relationships, but with a computational cost.\n",
    "\n",
    "* Third, we have to define the structure of the activation function (if any) of the output layer. The nature of the output function is often determined by the goal of the network. Here are some common output layer patterns:\n",
    "\n",
    "Binary classification: One unit with a sigmoid activation function.\n",
    "\n",
    "Multiclass classification: k units (where k is the number of target classes) and a softmax activation function.\n",
    "\n",
    "Regression: One unit with no activation function.\n",
    "\n",
    "* Fourth, we need to define a loss function (the function that measures how well a predicted value matches the true value); this is again often determined by the problem type:\n",
    "\n",
    "Binary classification: Binary cross-entropy.\n",
    "Multiclass classification: Categorical cross-entropy.\n",
    "Regression: Mean square error.\n",
    "\n",
    "* Fifth, we have to define an optimizer, which intuitively can be thought of as our strategy “walking around” the loss function to find the parameter values that produce the lowest error. Common choices for optimizers are stochastic gradient descent, stochastic gradient descent with momentum, root mean square propagation, and adaptive moment estimation (more information on these optimizers in “See Also”).\n",
    "\n",
    "* Sixth, we can select one or more metrics to use to evaluate the performance, such as accuracy.\n",
    "\n",
    "Keras offers two ways for creating neural networks. Keras’ sequential model creates neural networks by stacking together layers. An alternative method for creating neural networks is called the functional API, but that is more for researchers rather than practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01fd7c",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c618035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import  numpy  as  np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Specify the number of features you want to use\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load movie criticism data and target vectors\n",
    "# (data_train, target_train), (data_test, target_test) = imdb.load_data(num_words = number_of_features)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = number_of_features)\n",
    "# One-hot encode movie criticism data and convert it to a feature matrix\n",
    "tokenizer = Tokenizer(num_words = number_of_features)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode = \"binary\")\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode = \"binary\")\n",
    "\n",
    "# Start creating neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Added fully connected layer using ReLU as activation function\n",
    "network.add(layers.Dense(units = 16, activation = \"relu\", input_shape = (number_of_features,)))\n",
    "\n",
    "# Added fully connected layer using ReLU as activation function\n",
    "network.add(layers.Dense(units = 16, activation = \"relu\"))\n",
    "\n",
    "# Added fully connected layer that uses sigmoid function as activation function\n",
    "network.add(layers.Dense(units = 1, activation = \"sigmoid\")) #  sigmoid activation function\n",
    "\n",
    "#Compile neural network\n",
    "network.compile ( loss = \"binary_crossentropy\" , # cross entropy Binary classification: Binary cross-entropy.\n",
    "                  optimizer = \"rmsprop\" ,        # root mean square propagation method\n",
    "                  metrics = [ \"accuracy\" ])      # performance indicators は accuracy\n",
    "\n",
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f083506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training neural networks\n",
    "History  =  network.fit ( X_train , # feature value\n",
    "                          y_train , # target vector\n",
    "                          epochs = 10 , # number of epochs\n",
    "                          verbose = 1 , # Display status for each epoch\n",
    "                          batch_size = 128 , # Number of observations per batch (100)\n",
    "                          validation_data = (X_test , y_test )) #test data\n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "\n",
    "# Display the shape of the feature matrix\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2439d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Batch Gradient Descent. Batch Size = Size of Training Set\n",
    "# Stochastic Gradient Descent. Batch Size = 1\n",
    "# Mini-Batch Gradient Descent. 1 < Batch Size < Size of Training Set\n",
    "\n",
    "# In the case of mini-batch gradient descent, \n",
    "# popular batch sizes include 32, 64, and 128 samples. \n",
    "\n",
    "# Epoch: One pass through all of the rows in the training dataset.\n",
    "# Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "# One epoch is comprised of one or more batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9e25a",
   "metadata": {},
   "source": [
    "In this above example, we train that neural network using real data. We use 50,000 movie reviews (25,000 as training data, 25,000 held out for testing), categorized as positive or negative. We convert the text of the reviews into 1,000 binary features indicating the presence of one of the 1,000 most frequent words. Put more simply, our neural networks will use 25,000 observations, each with 1,000 features, to predict if a movie review is positive or negative.\n",
    "\n",
    "The epochs parameter defines how many epochs to use when training the data. verbose determines how much information is outputted during the training process, with 0 being no output, 1 outputting a progress bar, and 2 one log line per epoch. batch_size sets the number of observations to propagate through the network before updating the parameters.\n",
    "\n",
    "Finally, we held out a test set of data to use to evaluate the model. These test features and test target vector can be arguments of validation_data, which will use them for evaluation. Alternatively, we could have used validation_split to define what fraction of the training data we want to hold out for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fbc593",
   "metadata": {},
   "source": [
    "# Testing accuracy\n",
    "#### We can evaluate our model on the training set and testing set using the evaluate() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9539048",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = network.evaluate(X_train, y_train)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1] * 100))\n",
    "\n",
    "scores = network.evaluate(X_test, y_test)\n",
    "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f0f5d",
   "metadata": {},
   "source": [
    "## Training a Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 5000\n",
    "\n",
    "# data_train = X_train\n",
    "# target_vector_train = y_vector_train\n",
    "# data_test = X_test\n",
    "# target_vector_test = X_test\n",
    "\n",
    "# Load feature and target data\n",
    "data = reuters.load_data(num_words = number_of_features)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 5000\n",
    "\n",
    "# data_train = X_train\n",
    "# target_vector_train = y_vector_train\n",
    "# data_test = X_test\n",
    "# target_vector_test = X_test\n",
    "\n",
    "# Load feature and target data\n",
    "data = reuters.load_data(num_words = number_of_features)\n",
    "\n",
    "(X_train, y_vector_train), (X_test, y_vector_test) = data\n",
    "\n",
    "# Convert feature data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words = number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(X_train, mode = \"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(X_test, mode = \"binary\")\n",
    "\n",
    "# One-hot encode target vector to create a target matrix\n",
    "target_train = to_categorical(y_vector_train)\n",
    "target_test = to_categorical(y_vector_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# input shape is 8 because 8 features\n",
    "# activation = rectified linear unit  ReLU=max (0,z) sum weighted\n",
    "# fully connected by using 12 nodes  hiden layers\n",
    "\n",
    "#  https://keras.io/api/layers/core_layers/\n",
    "# -------------- ReLU ------\n",
    "# Binary classification:\n",
    "# One unit with a sigmoid activation function.\n",
    "# Multiclass classification:\n",
    "# k units (where k is the number of target classes) and a softmax activation func‐ tion.\n",
    "# Regression:\n",
    "# One unit with no activation function.\n",
    "# ----------------\n",
    "\n",
    "# ------- loss function -------\n",
    "# Binary classification:      Binary cross-entropy.\n",
    "# Multiclass classification:  Categorical cross-entropy.\n",
    "# Regression:                 Mean square error.\n",
    "# ------------------\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units = 100,\n",
    "                         activation = \"relu\",\n",
    "                         input_shape = (number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units = 100, activation = \"relu\"))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units = 46, activation = \"softmax\"))  \n",
    "# k units (where k is the number of target classes) and a softmax activation function.\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss = \"categorical_crossentropy\", # Multiclass classification: Categorical cross-entropy.\n",
    "                optimizer = \"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics = [\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs = 3, # Three epochs\n",
    "                      verbose = 1, # No output\n",
    "                      batch_size = 100, # Number of observations per batch\n",
    "                      validation_data = (features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = network.evaluate(features_train, target_train)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1] * 100))\n",
    "\n",
    "scores = network.evaluate(features_test, target_test)\n",
    "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc62a8",
   "metadata": {},
   "source": [
    "We created a similar neural network to the binary classifier, but with some notable changes. First, our data is 11,228 Reuters newswires. Each newswire is categorized into 46 topics. We prepared our feature data by converting the newswires into 5,000 binary features (denoting the presence of a certain word in the newswires). We prepared the target data by one-hot encoding it so that we obtain a target matrix denoting which of the 46 classes an observation belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View target matrix\n",
    "target_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47ea69",
   "metadata": {},
   "source": [
    "Second, we increased the number of units in each of the hidden layers to help the neural network represent the more complex relationship between the 46 classes.\n",
    "\n",
    "Third, since this is a multiclass classification problem, we used an output layer with 46 units (one per class) containing a softmax activation function. The softmax activation function will return an array of 46 values summing to 1. These 46 values represent an observation’s probability of being a member of each of the 46 classes.\n",
    "\n",
    "Fourth, we used a loss function suited to multiclass classification, the categorical cross-entropy loss function, categorical_crossentropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd57a2a0",
   "metadata": {},
   "source": [
    "## Training a Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3e1d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3) (10000,) 3\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features = 3,\n",
    "                                   n_informative = 3,\n",
    "                                   n_targets = 1,\n",
    "                                   noise = 0.0,\n",
    "                                   random_state = 0)\n",
    "\n",
    "# Divide our data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.33, random_state=61)\n",
    "print(features.shape, target.shape, features_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bffb0919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,153\n",
      "Trainable params: 17,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# input shape is 3 features\n",
    "# activation = rectified linear unit  ReLU=max (0,z) sum weighted\n",
    "# fully connected by using 12 nodes  hiden layers\n",
    "\n",
    "#  https://keras.io/api/layers/core_layers/\n",
    "# -------------- ReLU ------\n",
    "# Binary classification:\n",
    "# One unit with a sigmoid activation function.\n",
    "# Multiclass classification:\n",
    "# k units (where k is the number of target classes) and a softmax activation func‐ tion.\n",
    "# Regression:\n",
    "# One unit with no activation function.\n",
    "# ----------------\n",
    "\n",
    "# ------- loss function -------\n",
    "# Binary classification:      Binary cross-entropy.\n",
    "# Multiclass classification:  Categorical cross-entropy.\n",
    "# Regression:                 Mean square error.\n",
    "# ------------------\n",
    "\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=128,  # 32 \n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(features_train.shape[1],))) # flatten features\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))  # Regression: One unit with no activation function.\n",
    "\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"mse\", # Mean squared error for regression\n",
    "                optimizer=\"RMSprop\", # Optimization algorithm\n",
    "                metrics=[\"mse\"]) # Mean squared error\n",
    "\n",
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd954831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 19:52:17.363878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-14 19:52:17.711643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=10, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=128, # Number of observations per batch (100)\n",
    "                      validation_data=(features_test, target_test)) # Test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bfee3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 237.18928629 -105.62373505 -107.28840641 ...   38.45133325 -124.47858138\n",
      " -182.72590486]\n",
      "[[ 239.81085 ]\n",
      " [-106.59411 ]\n",
      " [-108.757835]\n",
      " ...\n",
      " [  40.359066]\n",
      " [-125.60709 ]\n",
      " [-182.85776 ]]\n",
      "(6700, 3) (3300, 3) (6700,) (3300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 19:52:37.398088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Predict classes of test set\n",
    "predicted_target = network.predict(features_test)\n",
    "\n",
    "print(target_test)\n",
    "print(predicted_target)\n",
    "\n",
    "print(features_train.shape, features_test.shape, target_train.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8edd3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 1s 3ms/step - loss: 3.6543 - mse: 3.6543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6542694568634033, 3.6542694568634033]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = network.evaluate(features_train, target_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e70e16",
   "metadata": {},
   "source": [
    "# Mean squared error (MSE) \n",
    " measures the amount of error in statistical models. \n",
    "It assesses the average squared difference between the observed and predicted values. \n",
    "When a model has no error, the MSE equals zero.\n",
    " \n",
    "Simply put, the lower the value the better and 0 means the model is perfect. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72af05c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 1s 3ms/step - loss: 3.6543 - mse: 3.6543\n",
      "Training MSE: 3.65%\n",
      "\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 3.8472 - mse: 3.8472\n",
      "Testing MSE: 3.85%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = network.evaluate(features_train, target_train)\n",
    "print(\"Training MSE: %.2f%%\\n\" % (scores[1]))\n",
    "\n",
    "scores = network.evaluate(features_test, target_test)\n",
    "print(\"Testing MSE: %.2f%%\\n\" % (scores[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9d05d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history[\"loss\"]\n",
    "test_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb592b",
   "metadata": {},
   "source": [
    "It is completely possible to create a neural network to predict continuous values instead of class probabilities. In the case of our binary classifier, we used an output layer with a single unit and a sigmoid activation function to produce a probability that an observation was class 1. Importantly, the sigmoid activation function constrained the outputted value to between 0 and 1. If we remove that constraint by having no activation function, we allow the output to be a continuous value.\n",
    "\n",
    "Furthermore, because we are training a regression, we should use an appropriate loss function and evaluation metric, in our case the mean square error:\n",
    "\n",
    "MSE = 1 n ∑ i=1 n (y i ^-y i ) 2\n",
    "where n is the number of observations; yi is the true value of the target we are trying to predict, y, for observation i; and ŷi is the model’s predicted value for yi.\n",
    "\n",
    "Finally, because we are using simulated data using scikit-learn, make_regression, we didn’t have to standardize the features. It should be noted, however, that in almost all real-world cases standardization would be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8285bd",
   "metadata": {},
   "source": [
    "## Visualize Training History\n",
    "You want to find the “sweet spot” in a neural network’s loss and/or accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 10000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words = number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode = \"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode = \"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs=15, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=1000, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history[\"loss\"]\n",
    "test_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4baa2cb",
   "metadata": {},
   "source": [
    "Alternatively, we can use the same approach to visualize the training and test accuracy over each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history[\"accuracy\"]\n",
    "test_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.plot(epoch_count, training_accuracy, \"r--\")\n",
    "plt.plot(epoch_count, test_accuracy, \"b-\")\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.legend([\"Training Accuracy\", \"Test Accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e9fe2",
   "metadata": {},
   "source": [
    "When our neural network is new, it will have a poor performance. As the neural network learns on the training data, the model’s error on both the training and test set will tend to decrease. However, at a certain point the neural network starts “memorizing” the training data, and overfits. When this starts happening, the training error will decrease while the test error will start increasing. Therefore, in many cases there is a “sweet spot” where the test error (which is the error we mainly care about) is at its lowest point. This effect can be plainly seen in the solution where we visualize the training and test loss at each epoch. Note that the test error is lowest around epoch five, after which the training loss continues to decrease while the test loss starts increasing. At this point onward, the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7e539",
   "metadata": {},
   "source": [
    "## k-Fold Cross-Validating Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a063ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of features\n",
    "number_of_features = 100\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = number_of_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 0)\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "\n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\n",
    "        number_of_features,)))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                    optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network,\n",
    "                                 epochs=10,\n",
    "                                 batch_size=100,\n",
    "                                 verbose=0)\n",
    "\n",
    "# Evaluate neural network using three-fold cross-validation\n",
    "cross_val_score(neural_network, features, target, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bcda7",
   "metadata": {},
   "source": [
    "Theoretically, there is no reason we cannot use cross-validation to evaluate neural networks. However, neural networks are often used on very large data and can take hours or even days to train. For this reason, if the training time is long, adding the computational expense of k-fold cross-validation is unadvisable. For example, a model normally taking one day to train would take 10 days to evaluate using 10-fold cross-validation. If we have large data, it is often appropriate to simply evaluate the neural network on some test set.\n",
    "\n",
    "If we have smaller data, k-fold cross-validation can be useful to maximize our ability to evaluate the neural network’s performance. This is possible in Keras because we can “wrap” any neural network such that it can use the evaluation features available in scikit-learn, including k-fold cross-validation. To accomplish this, we first have to create a function that returns a compiled neural network. Next we use KerasClassifier (if we have a classifier; if we have a regressor we can use KerasRegressor) to wrap the model so it can be used by scikit-learn. After this, we can use our neural network like any other scikit-learn learning algorithm (e.g., random forests, logistic regression). In our solution, we used cross_val_score to run a three-fold cross-validation on our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0822b",
   "metadata": {},
   "source": [
    "## CASE StUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c906d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from utils import preprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(16)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('diabetes.csv')\n",
    "except:\n",
    "    print(\"\"\"\n",
    "      Dataset not found in your computer.\n",
    "      Please follow the instructions in the link below to download the dataset:\n",
    "      https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/chapter2/how_to_download_the_dataset.txt\n",
    "      \"\"\")\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec375c",
   "metadata": {},
   "source": [
    "# Visualization of diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f204a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt    \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# look at the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe073fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['Glucose'] = df['Glucose'].replace(0, np.nan)\n",
    "df['BloodPressure'] = df['BloodPressure'].replace(0, np.nan)\n",
    "df['SkinThickness'] = df['SkinThickness'].replace(0, np.nan)\n",
    "df['Insulin'] = df['Insulin'].replace(0, np.nan)\n",
    "df['BMI'] = df['BMI'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1380a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 0 values for each variable\n",
      "Pregnancies: 111\n",
      "Glucose: 0\n",
      "BloodPressure: 0\n",
      "SkinThickness: 0\n",
      "Insulin: 0\n",
      "BMI: 0\n",
      "DiabetesPedigreeFunction: 0\n",
      "Age: 0\n",
      "Outcome: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows with 0 values for each variable\")\n",
    "for col in df.columns:    \n",
    "    missing_rows = df.loc[df[col]==0].shape[0]    \n",
    "    print(col + \": \" + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1dcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose'] = df['Glucose'].fillna(df['Glucose'].mean())\n",
    "df['BloodPressure'] = df['BloodPressure'].fillna(df['BloodPressure'].mean())\n",
    "df['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].mean())\n",
    "df['Insulin'] = df['Insulin'].fillna(df['Insulin'].mean())\n",
    "df['BMI'] = df['BMI'].fillna(df['BMI'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e63cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df_scaled = preprocessing.scale(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "df_scaled['Outcome'] = df['Outcome']\n",
    "df = df_scaled\n",
    "print(df.describe().loc[['mean', 'std','max'],].round(2).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.loc[:, df.columns != 'Outcome']\n",
    "y = df.loc[:, 'Outcome']\n",
    "\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffa51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# Build neural network in Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=8))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=200, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05eefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results - Accuracy\n",
    "scores = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1]*100))\n",
    "scores = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "ax = sns.heatmap(c_matrix, annot=True,                  \n",
    "                 xticklabels=['No Diabetes','Diabetes'],                \n",
    "                 yticklabels=['No Diabetes','Diabetes'],                  \n",
    "                 cbar=False, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d929a25",
   "metadata": {},
   "source": [
    "# ANN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154903bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231926d9",
   "metadata": {},
   "source": [
    "The dataset describes 13 numerical properties of houses in Boston suburbs and is concerned with modeling the price of houses in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem. Input attributes include things like crime rate, proportion of nonretail business acres, chemical concentrations and more.\n",
    "\n",
    "This is a well-studied problem in machine learning. It is convenient to work with because all of the input and output attributes are numerical and there are 506 instances to work with.\n",
    "\n",
    "Reasonable performance for models evaluated using Mean Squared Error (MSE) are around 20 in squared thousands of dollars (or $4,500 if you take the square root). This is a nice target to aim for with our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc77af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(\"housing.csv\", delim_whitespace = True, header = None)\n",
    "df = dataframe.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = df[:,0:13]\n",
    "y = df[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d61635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    # `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
    "    model = Sequential()\n",
    "    # Adds a layer instance on top of the layer stack. # Create a `Sequential` model and add a Dense layer as the first layer.\n",
    "    model.add(Dense(20, input_dim = 13, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    # The efficient ADAM optimization algorithm is used and a mean squared error loss function is optimized. \n",
    "    # This will be the same metric that we will use to evaluate the performance of the model.\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Kfold Cross Validation\n",
    "estimator = KerasRegressor(build_fn = baseline_model, epochs = 100, batch_size = 5, verbose = 0)\n",
    "kfold = KFold(n_splits = 10)\n",
    "results = cross_val_score(estimator, X, y, cv = kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = wider_model, epochs = 100, \n",
    "                                         batch_size = 5, verbose = 0)))\n",
    "# The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits = 10)\n",
    "results = cross_val_score(pipeline, X, y, cv = kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc25a2e",
   "metadata": {},
   "source": [
    "# Task\n",
    "Apply ANN to Predict Average Daily Rates for Hotels. Data set (H1) is available on Moodle. Use the following features (independent) for ANN and target feature customer (ADR) from the given dataset.\n",
    "\n",
    "#### Independent Features\n",
    "* IsCanceled\n",
    "* Country\n",
    "* MarketSegment\n",
    "* DepositType\n",
    "* CustomerType\n",
    "* RequiredCarParkingSpaces\n",
    "* ArrivalDateWeekNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e82341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be878a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset named as 'H1.csv'\n",
    "train_df = pd.read_csv('H1.csv')\n",
    "\n",
    "# Displau the records\n",
    "a = train_df.head()\n",
    "\n",
    "# Store the training records into 'b' dataframe\n",
    "b = train_df\n",
    "\n",
    "# Sort the values of the dataframe (b)\n",
    "b.sort_values(['ArrivalDateYear','ArrivalDateWeekNumber'], ascending = True)\n",
    "\n",
    "# Display the dataframe \n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bee62",
   "metadata": {},
   "source": [
    "## Reference\n",
    "* Chapter 20, Machine Learning with Python Cookbook, Chris Albon, O'Reilly Media, Inc., 2018.\n",
    "* <p>machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 GPU tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
